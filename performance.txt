model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.922632611714876, 4.036729895151579, 3.8816620386563816, 3.6505901630108175, 3.6759786239037147, 3.466539823091947, 3.455458787771372, 3.4583221398867092, 3.416807844088628, 3.355407797373258, 3.1480420644466696, 3.218435149926406, 3.168899316054124, 2.9695792473279514, 2.8585566924168515, 2.996044635772705, 2.8057164503977847, 2.6460161805152893, 2.613515074436481, 2.428000482229086, 2.570987288768475, 2.3819931699679446, 2.3496998044160695, 2.25555171416356, 2.1336327561965356, 2.152414757471818, 2.24179902443519, 2.1133943704458384, 2.0893990993499756, 2.085450456692622, 1.9600751904340892, 2.0258871133510885, 1.9012891191702623, 1.9132736783761244, 1.8485893332041228, 1.9429636689332814, 1.878594682766841, 1.895644527215224, 1.803406027647165, 1.833853318141057, 1.803496819276076, 1.8619380730849047, 1.8017963079305797, 1.7516177159089308, 1.7258853224607615, 1.7825269607397227, 1.7153519254464369, 1.7314565823628352, 1.6772801463420575, 1.7126356684244597, 1.6945119821108305, 1.7009422549834619, 1.6473592657309313, 1.6918370035978465, 1.6944601306548486, 1.737441136286809, 1.6692374807137709, 1.6911334945605352, 1.7335485907701345, 1.6181397162950957, 1.5745103726020226, 1.5495901612135081, 1.542045730810899, 1.5266102781662574, 1.5271670772479131, 1.5147724335010235, 1.5138207903275123, 1.5016512183042674, 1.5006068348884583, 1.5087882968095632, 1.5142001188718355, 1.5034945056988642, 1.5055288351499116, 1.490307642863347, 1.476063636633066, 1.4751273439480708, 1.4708789403621967, 1.5002684914148772, 1.5148723767353938, 1.4980643666707552, 1.4766660607778108, 1.4693406866146967, 1.4633621986095722, 1.4602042986796453, 1.4557672922427838, 1.4560278975046599, 1.4535891321989207, 1.452588636141557, 1.4533508099042451, 1.4378865040265596, 1.436768820652595, 1.4423185816177955, 1.4422569687549884, 1.4662431616049547, 1.4410085311302772, 1.4503330267392671, 1.4398173506443317, 1.417029389968285, 1.3978274327058058, 1.3901380896568298]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.5003211406284676, None, None, None, None, None, None, None, None, None, 3.3905304396562075, None, None, None, None, None, None, None, None, None, 2.261845107391845, None, None, None, None, None, None, None, None, None, 2.1910521961106384, None, None, None, None, None, None, None, None, None, 1.9452639445258308, None, None, None, None, None, None, None, None, None, 1.8990367852901393, None, None, None, None, None, None, None, None, None, 1.8345895465272533, None, None, None, None, None, None, None, None, None, 1.8084309402900407, None, None, None, None, None, None, None, None, None, 1.796671295970804, None, None, None, None, None, None, None, None, None, 1.7682237888834]
best validation loss: 1.7682237888834
training time: 4460.65 seconds
batch size: 64 -> 128
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=128, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [5.566517426417424, 3.7823475690988393, 3.8023419930384708, 3.43500148333036, 3.4269931132976827, 3.367046906397893, 3.3572947061978855, 3.341971415739793, 3.2077980591700626, 3.1990480422973633, 3.1779722433823805, 3.1371398705702562, 3.0845931676717906, 3.0620249601510854, 3.207105049720177, 2.982035215084369, 2.8106033618633566, 2.764224052429199, 2.6741527043856106, 2.6373070753537693, 2.4985158993647647, 2.665068653913645, 2.5387313916133, 2.464568073932941, 2.4950561890235314, 2.3088828783768873, 2.2119991962726298, 2.2619830553348246, 2.3519942485369167, 2.0979722921664896, 2.094728313959562, 2.0925282331613393, 2.051515276615436, 2.0365159053068895, 1.947262818996723, 1.911273534481342, 1.8801061098392193, 1.8801262286993174, 1.8457859204365656, 1.8530126168177679, 1.8625970987173228, 1.810350353901203, 1.7849546946012056, 1.7666313373125517, 1.805323334840628, 1.7625148754853468, 1.7493493190178504, 1.7791732182869544, 1.7041994608365572, 1.7840421566596398, 1.6880828967461219, 1.6898122567396898, 1.7068802576798658, 1.7217308007753813, 1.6779333903239324, 1.6392040527783907, 1.6437761600200946, 1.6029761296052198, 1.6198977323678823, 1.5902892717948327, 1.6131623524885912, 1.6183104423376231, 1.6001049463565533, 1.5991850816286528, 1.5881209465173574, 1.555925726890564, 1.585494509110084, 1.5566148574535663, 1.5368850689667921, 1.5432660304583037, 1.549055475455064, 1.5228902468314538, 1.5520374591533954, 1.5328697241269624, 1.5110434018648589, 1.5114895747258112, 1.5185741369540875, 1.4941336925213153, 1.5064526612942035, 1.5450437985933745, 1.5486147862214308, 1.5392028735234187, 1.5262176623711219, 1.5072609094473033, 1.4613988674603975, 1.4535763905598567, 1.4234225474871123, 1.4187905054826002, 1.4268746651135957, 1.4152390956878662, 1.4086512693992028, 1.4193105697631836, 1.4189611214857836, 1.4168791770935059, 1.4303884414526133, 1.4180114544354951, 1.4302532030985906, 1.3848326481305635, 1.3787988057503333, 1.381409425001878]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.4910062000362037, None, None, None, None, None, None, None, None, None, 2.893611993827038, None, None, None, None, None, None, None, None, None, 2.541195647985264, None, None, None, None, None, None, None, None, None, 2.278748321418233, None, None, None, None, None, None, None, None, None, 2.068328783338224, None, None, None, None, None, None, None, None, None, 1.9662009153544293, None, None, None, None, None, None, None, None, None, 1.9023979170053675, None, None, None, None, None, None, None, None, None, 1.9139575540049383, None, None, None, None, None, None, None, None, None, 1.8116970253393117, None, None, None, None, None, None, None, None, None, 1.7927402460553548]
best validation loss: 1.7927402460553548
training time: 4369.86 seconds
batch size: 128 -> 64, learning rate: 0.0005 -> 0.001
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.001, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [5.199583475406353, 4.014510897489695, 4.0149229764938354, 3.7487172805345974, 3.6305332550635705, 3.7064108573473415, 3.697945448068472, 3.4906577605467577, 3.3147521569178653, 3.5265718606802134, 3.2326912788244395, 3.0340383603022647, 3.0339631209006677, 2.999288458090562, 3.0522386202445397, 2.8254581689834595, 2.779553165802589, 2.604121730877803, 2.6139597296714783, 2.5302259096732507, 2.5003329790555515, 2.405216400439923, 2.458961165868319, 2.285484396494352, 2.176844156705416, 2.1760796858714175, 2.218895334463853, 2.074225971331963, 2.1121890865839443, 2.086629963838137, 2.0137690626657925, 1.9870423720433161, 1.9346304627565236, 1.9153633988820589, 1.9546769123810988, 1.923130370103396, 1.8741858509870677, 1.9282606289936945, 1.8647669920554528, 1.885241334254925, 1.8755681606439443, 1.872596685702984, 1.8350001344313989, 1.8101976422163157, 1.8208642968764672, 1.835833659538856, 1.8478216895690331, 1.8264204630484948, 1.8353691009374766, 1.7862525857411897, 1.7550782423753004, 1.7937155457643361, 1.7618639744245088, 1.7711966679646418, 1.770344037276048, 1.7649027751042292, 1.7677619044597332, 1.7093913463445811, 1.631780220912053, 1.6517512110563426, 1.6087527504334083, 1.6042230358490577, 1.6184723331378057, 1.5956614934481108, 1.5894450499461248, 1.586637020111084, 1.5705161736561701, 1.570318116591527, 1.5620461748196528, 1.564644034092243, 1.559355107637552, 1.5797383372600262, 1.5756069330068736, 1.5917685536237864, 1.5726815462112427, 1.5471711708949163, 1.5577750618641193, 1.554964808317331, 1.5505378658954914, 1.5457941798063426, 1.5340563929997957, 1.54198380616995, 1.5404512515434852, 1.5600016025396495, 1.5320474963921766, 1.5332467601849482, 1.5391016969313989, 1.5353054266709547, 1.5297568761385405, 1.5236062636742225, 1.5200026493806105, 1.5195911755928626, 1.519911147080935, 1.5133073696723351, 1.512821587232443, 1.508965029166295, 1.5011730056542616, 1.5068755195691035, 1.5102045352642353, 1.4919288571064289]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.5669112020116605, None, None, None, None, None, None, None, None, None, 3.1965255396706715, None, None, None, None, None, None, None, None, None, 2.2754012580518626, None, None, None, None, None, None, None, None, None, 2.211513362065937, None, None, None, None, None, None, None, None, None, 2.0702184097388914, None, None, None, None, None, None, None, None, None, 1.954317137446297, None, None, None, None, None, None, None, None, None, 1.9157265799098737, None, None, None, None, None, None, None, None, None, 1.8716355848915969, None, None, None, None, None, None, None, None, None, 1.880022226003655, None, None, None, None, None, None, None, None, None, 1.8362377194340793]
best validation loss: 1.8362377194340793
training time: 4544.45 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0001, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [5.863162462527935, 3.9896199794916005, 3.764358025330764, 3.552787368114178, 3.4885537165861864, 3.371530221058772, 3.312395508472736, 3.3383218875298133, 3.223294707444998, 3.228035284922673, 3.1959158273843618, 3.1714029037035427, 3.1626409659018884, 3.033599385848412, 2.959498781424302, 2.961499205002418, 2.911282631067129, 3.0118228930693407, 2.846810432580801, 2.7999393114676843, 2.6657459277373095, 2.661839925325834, 2.6466389252589297, 2.5027293883837185, 2.454161043350513, 2.335680168408614, 2.2811110661580014, 2.251555025577545, 2.2429229571269107, 2.1231259520237264, 2.12093938772495, 2.0104006207906284, 2.017846336731544, 1.969664963392111, 1.988075201327984, 1.9172261265607982, 1.8505555712259734, 1.8312586454244761, 1.8378138037828298, 1.8556158542633057, 1.9221643805503845, 1.8845186600318322, 1.7842048360751226, 1.7229912556134737, 1.7433932286042433, 1.732372380219973, 1.7337720348284795, 1.7230750643290007, 1.6679118871688843, 1.6529438266387353, 1.6813088196974535, 1.7458331951728234, 1.6800842055907617, 1.675129459454463, 1.6706589047725384, 1.5982043926532452, 1.6317937511664171, 1.5927840242019067, 1.608986639059507, 1.6039979641254132, 1.5857419050656831, 1.5774411238156831, 1.5737256636986365, 1.5666111432589018, 1.5549093439028814, 1.5550679931273828, 1.5338041690679698, 1.5447026949662428, 1.5322632789611816, 1.5273857575196486, 1.5368766738818243, 1.5464066083614643, 1.5557961601477404, 1.5457006417787993, 1.5032369631987352, 1.5145302002246563, 1.4992966468517597, 1.5042546345637395, 1.496546474786905, 1.5098168758245616, 1.492571573991042, 1.5228598713874817, 1.5017406757061298, 1.4932602552267222, 1.4846081550304706, 1.4876215916413527, 1.4796531017010028, 1.4889112344154944, 1.4786292406228871, 1.4717948207488427, 1.4767114841021025, 1.483882514330057, 1.4721355025584881, 1.4670795110555797, 1.4494476089110742, 1.45362395965136, 1.4419856438269982, 1.4439089665046105, 1.442679877464588, 1.4248638153076172]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.4471336352386843, None, None, None, None, None, None, None, None, None, 2.9980500222258426, None, None, None, None, None, None, None, None, None, 2.469132972668998, None, None, None, None, None, None, None, None, None, 2.086564657269938, None, None, None, None, None, None, None, None, None, 2.0300522947110204, None, None, None, None, None, None, None, None, None, 1.9103070516913967, None, None, None, None, None, None, None, None, None, 1.881503158337097, None, None, None, None, None, None, None, None, None, 1.850471495073053, None, None, None, None, None, None, None, None, None, 1.86019478769745, None, None, None, None, None, None, None, None, None, 1.8103103473144817]
best validation loss: 1.8103103473144817
training time: 4359.83 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=200, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.922632611714876, 4.036729895151579, 3.8816620386563816, 3.6505901630108175, 3.6759786239037147, 3.466539823091947, 3.455458787771372, 3.4583221398867092, 3.416807844088628, 3.355407797373258, 3.1480420644466696, 3.218435149926406, 3.168899316054124, 2.9695792473279514, 2.8585566924168515, 2.996044635772705, 2.8057164503977847, 2.6460161805152893, 2.613515074436481, 2.428000482229086, 2.570987288768475, 2.3819931699679446, 2.3496998044160695, 2.25555171416356, 2.1336327561965356, 2.152414757471818, 2.24179902443519, 2.1133943704458384, 2.0893990993499756, 2.085450456692622, 1.9600751904340892, 2.0258871133510885, 1.9012891191702623, 1.9132736783761244, 1.8485893332041228, 1.9429636689332814, 1.878594682766841, 1.895644527215224, 1.803406027647165, 1.833853318141057, 1.803496819276076, 1.8619380730849047, 1.8017963079305797, 1.7516177159089308, 1.7258853224607615, 1.7825269607397227, 1.7153519254464369, 1.7314565823628352, 1.6772801463420575, 1.7126356684244597, 1.6945119821108305, 1.7009422549834619, 1.6473592657309313, 1.6918370035978465, 1.6944601306548486, 1.737441136286809, 1.6692374807137709, 1.6911334945605352, 1.7335485907701345, 1.6181397162950957, 1.5745103726020226, 1.5495901612135081, 1.542045730810899, 1.5266102781662574, 1.5271670772479131, 1.5147724335010235, 1.5138207903275123, 1.5016512183042674, 1.5006068348884583, 1.5087882968095632, 1.5142001188718355, 1.5034945056988642, 1.5055288351499116, 1.490307642863347, 1.476063636633066, 1.4751273439480708, 1.4708789403621967, 1.5002684914148772, 1.5148723767353938, 1.4980643666707552, 1.4766660607778108, 1.4693406866146967, 1.4633621986095722, 1.4602042986796453, 1.4557672922427838, 1.4560278975046599, 1.4535891321989207, 1.452588636141557, 1.4533508099042451, 1.4378865040265596, 1.436768820652595, 1.4423185816177955, 1.4422569687549884, 1.4662431616049547, 1.4410085311302772, 1.4503330267392671, 1.4398173506443317, 1.417029389968285, 1.3978274327058058, 1.3901380896568298, 1.3861601031743562, 1.383396098246941, 1.3845388430815477, 1.3766711812752943, 1.3769157803975618, 1.3734785685172448, 1.3757176811878498, 1.372527920282804, 1.3714931561396673, 1.3709290394416223, 1.364536973146292, 1.369910098039187, 1.3729673027992249, 1.368946176308852, 1.3700972061890822, 1.3680526384940515, 1.3673728704452515, 1.3491221712185786, 1.3495908150306115, 1.3509477560336773, 1.3508705496788025, 1.3463070530157824, 1.3449663886657128, 1.345028547140268, 1.3446672512934759, 1.341133952140808, 1.345716627744528, 1.346269116951869, 1.3394661087256212, 1.3435064049867482, 1.3433310343669012, 1.3409545467450068, 1.3378841556035554, 1.3416029123159556, 1.339039949270395, 1.3402908719502962, 1.335195711025825, 1.3353993617571318, 1.3374855655890245, 1.3358959876574004, 1.3383717032579274, 1.3399390486570506, 1.3359746795434218, 1.3308265163348272, 1.3261538560573871, 1.329137426156264, 1.3287575932649465, 1.3283055837337787, 1.3270717446620648, 1.3247993771846478, 1.3241755366325378, 1.3243670830359826, 1.3244894330318158, 1.3246445518273573, 1.3245652593099153, 1.3226974056317256, 1.321664301248697, 1.3256509716694171, 1.3236285814872155, 1.3245794085355906, 1.3221344168369586, 1.3219540165020869, 1.3241863663379962, 1.3211315778585582, 1.3209868990457976, 1.3183653950691223, 1.3173798597775972, 1.3185588534061725, 1.320366313824287, 1.3160663889004633, 1.3199483752250671, 1.3210243032528803, 1.3193813103895922, 1.31815609565148, 1.3175378212561975, 1.3183558445710402, 1.3159789993212774, 1.3172072080465465, 1.3159054471896245, 1.3169473455502436, 1.31536911542599, 1.3188843131065369, 1.3191028604140649, 1.3197660125218904, 1.31545083797895, 1.3149517682882457, 1.3179220740611737, 1.3189303829119756, 1.316846719154945, 1.3172643184661865, 1.3184559161846454, 1.3205324044594398, 1.3142485664441035, 1.3143995679341829, 1.3147566731159503, 1.3132953689648554, 1.3168043219126189, 1.3145899039048414, 1.3130451074013343, 1.3151767070476825]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.5003211406284676, None, None, None, None, None, None, None, None, None, 3.3905304396562075, None, None, None, None, None, None, None, None, None, 2.261845107391845, None, None, None, None, None, None, None, None, None, 2.1910521961106384, None, None, None, None, None, None, None, None, None, 1.9452639445258308, None, None, None, None, None, None, None, None, None, 1.8990367852901393, None, None, None, None, None, None, None, None, None, 1.8345895465272533, None, None, None, None, None, None, None, None, None, 1.8084309402900407, None, None, None, None, None, None, None, None, None, 1.796671295970804, None, None, None, None, None, None, None, None, None, 1.7682237888834, None, None, None, None, None, None, None, None, None, 1.7728102974607112, None, None, None, None, None, None, None, None, None, 1.7701124378253783, None, None, None, None, None, None, None, None, None, 1.7719753568182515, None, None, None, None, None, None, None, None, None, 1.7664720699541392, None, None, None, None, None, None, None, None, None, 1.7689789659363309, None, None, None, None, None, None, None, None, None, 1.7743527076559085, None, None, None, None, None, None, None, None, None, 1.7727931015745857, None, None, None, None, None, None, None, None, None, 1.7727758666705913, None, None, None, None, None, None, None, None, None, 1.7729945197171515, None, None, None, None, None, None, None, None, None, 1.772519612901537]
best validation loss: 1.7664720699541392
training time: 9261.58 seconds
changed layernorm to rmsnorm
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [5.085341948729295, 3.7924481263527503, 3.9337205978540273, 3.7933543920516968, 3.512253632912269, 3.783166692807124, 3.334631241284884, 3.261135220527649, 3.300975414422842, 3.064303003824674, 3.118844646673936, 3.041794226719783, 2.8243177303901086, 2.7151352075430064, 2.4874596412365255, 2.409317236680251, 2.2808187695649953, 2.1070880568944492, 2.0792904862990746, 1.9929694625047536, 1.887497631403116, 1.9453985874469464, 2.0010118071849528, 1.9222093728872447, 1.8082105884185204, 1.7588766813278198, 1.7920339886958783, 1.8363519815298228, 1.7390391276432917, 1.757456816159762, 1.770611597941472, 1.806337874669295, 1.7279231731708233, 1.7593642381521373, 1.7206163543921251, 1.6762519616347094, 1.6784665676263661, 1.659498774088346, 1.684383328144367, 1.630573836656717, 1.6318805034344013, 1.6345405762012188, 1.6534307461518507, 1.6484937484447773, 1.6052798582957342, 1.6183966535788317, 1.611012509235969, 1.5995528239470262, 1.6220768231611986, 1.6289262634057264, 1.566552758216858, 1.5696021593534029, 1.5784847094462469, 1.5504844555488, 1.5451523524064283, 1.5694969434004564, 1.551786665733044, 1.5505589384299059, 1.541852749311007, 1.5674801973196177, 1.5399311322432299, 1.5247940421104431, 1.5032112094072194, 1.5087785078929021, 1.5164991892301118, 1.504363743158487, 1.4939007254747243, 1.5286683210959802, 1.5242234789408171, 1.4782363176345825, 1.504784574875465, 1.5013807645210853, 1.4836337703924913, 1.4775552291136522, 1.5042560559052687, 1.4557451926744902, 1.4461940068465013, 1.434535787655757, 1.4399966505857615, 1.4685059510744536, 1.4377229580512414, 1.456350381557758, 1.4335910356961763, 1.4432180982369642, 1.4739713072776794, 1.4583464173170237, 1.5155229981128986, 1.4505612712640028, 1.4495093043033893, 1.3938081814692571, 1.3722253716908968, 1.3737101096373339, 1.3751130287463849, 1.3529354884074285, 1.3531192311873803, 1.3464928819583013, 1.3575342022455656, 1.3588862740076506, 1.337885590700003, 1.3498571010736318]
validation loss history: [None, None, None, None, None, None, None, None, None, 3.679494319585808, None, None, None, None, None, None, None, None, None, 2.256642012369065, None, None, None, None, None, None, None, None, None, 2.104312717160092, None, None, None, None, None, None, None, None, None, 1.9270016000959225, None, None, None, None, None, None, None, None, None, 1.9002369967047317, None, None, None, None, None, None, None, None, None, 1.8590510243604959, None, None, None, None, None, None, None, None, None, 1.785173199419662, None, None, None, None, None, None, None, None, None, 1.7669864013440786, None, None, None, None, None, None, None, None, None, 1.708556096549491, None, None, None, None, None, None, None, None, None, 1.679872151884133]
best validation loss: 1.679872151884133
training time: 4628.40 seconds
changed sinusoidal positional encoding to rotary positional encoding and using in multi-head attention
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=100, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.502254788692181, 2.4429813760977526, 2.241055653645442, 2.185009236519153, 1.9990252210543706, 1.9283065704198985, 1.913086304297814, 1.8590233738605793, 1.7968204479951124, 1.7491724812067473, 1.735809339926793, 1.6901766107632563, 1.6924860385748057, 1.6501396069159875, 1.615222128537985, 1.6042131047982435, 1.6078883271950941, 1.5880984801512499, 1.6016942170950084, 1.5458030700683594, 1.583488744038802, 1.5413878514216497, 1.540492364993462, 1.5013051491517286, 1.518504417859591, 1.499844674880688, 1.509120184641618, 1.5001045923966627, 1.4894360624826872, 1.4996399054160485, 1.4855556258788476, 1.4791555312963633, 1.4492729627169096, 1.4378039424236004, 1.436497518649468, 1.4315949219923754, 1.4322317334321828, 1.4430199036231408, 1.42997760956104, 1.4172499088140635, 1.426828682422638, 1.4071223139762878, 1.417980698438791, 1.411879470715156, 1.4214310967005217, 1.3938842369959905, 1.3763525715241065, 1.3670963782530565, 1.3669722722126887, 1.360006923858936, 1.3749685791822581, 1.3538127266443694, 1.4194085460442762, 1.3763101330170264, 1.3718464512091417, 1.364512223463792, 1.3620753930165217, 1.3633923026231618, 1.3111355763215284, 1.2628802565427928, 1.2618387295649602, 1.249820379110483, 1.2484631217443025, 1.240002989768982, 1.2381010284790626, 1.2213502801381624, 1.2287410910312946, 1.2198630319191859, 1.202764550080666, 1.206654287301577, 1.212994974393111, 1.201858965250162, 1.2017474885170276, 1.1932327013749342, 1.1862080074273622, 1.1888651687365313, 1.1891689002513885, 1.189229625921983, 1.1731530473782465, 1.1684247690897722, 1.1687721816393046, 1.1595607950137212, 1.1634962581671202, 1.1544357331899495, 1.1509192448395948, 1.1453031989244313, 1.1409633228412042, 1.1391377105162694, 1.1422647673350115, 1.1351347749049847, 1.1317315330872169, 1.1358092794051537, 1.1270367342692156, 1.1220297240293944, 1.1287718965457036, 1.1229915848145118, 1.1276325377134175, 1.1157567753241613, 1.104491882599317]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.9950126439710207, None, None, None, None, None, None, None, None, None, 1.7938135411812643, None, None, None, None, None, None, None, None, None, 1.7717145569644972, None, None, None, None, None, None, None, None, None, 1.676692353989289, None, None, None, None, None, None, None, None, None, 1.6423484380163293, None, None, None, None, None, None, None, None, None, 1.577425451074615, None, None, None, None, None, None, None, None, None, 1.5195799432582637, None, None, None, None, None, None, None, None, None, 1.4779543190781361, None, None, None, None, None, None, None, None, None, 1.464721017964566, None, None, None, None, None, None, None, None, None, 1.4339659000966403]
best validation loss: 1.4339659000966403
training time: 5660.69 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=200, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.502254788692181, 2.4429813760977526, 2.241055653645442, 2.185009236519153, 1.9990252210543706, 1.9283065704198985, 1.913086304297814, 1.8590233738605793, 1.7968204479951124, 1.7491724812067473, 1.735809339926793, 1.6901766107632563, 1.6924860385748057, 1.6501396069159875, 1.615222128537985, 1.6042131047982435, 1.6078883271950941, 1.5880984801512499, 1.6016942170950084, 1.5458030700683594, 1.583488744038802, 1.5413878514216497, 1.540492364993462, 1.5013051491517286, 1.518504417859591, 1.499844674880688, 1.509120184641618, 1.5001045923966627, 1.4894360624826872, 1.4996399054160485, 1.4855556258788476, 1.4791555312963633, 1.4492729627169096, 1.4378039424236004, 1.436497518649468, 1.4315949219923754, 1.4322317334321828, 1.4430199036231408, 1.42997760956104, 1.4172499088140635, 1.426828682422638, 1.4071223139762878, 1.417980698438791, 1.411879470715156, 1.4214310967005217, 1.3938842369959905, 1.3763525715241065, 1.3670963782530565, 1.3669722722126887, 1.360006923858936, 1.3749685791822581, 1.3538127266443694, 1.4194085460442762, 1.3763101330170264, 1.3718464512091417, 1.364512223463792, 1.3620753930165217, 1.3633923026231618, 1.3111355763215284, 1.2628802565427928, 1.2618387295649602, 1.249820379110483, 1.2484631217443025, 1.240002989768982, 1.2381010284790626, 1.2213502801381624, 1.2287410910312946, 1.2198630319191859, 1.202764550080666, 1.206654287301577, 1.212994974393111, 1.201858965250162, 1.2017474885170276, 1.1932327013749342, 1.1862080074273622, 1.1888651687365313, 1.1891689002513885, 1.189229625921983, 1.1731530473782465, 1.1684247690897722, 1.1687721816393046, 1.1595607950137212, 1.1634962581671202, 1.1544357331899495, 1.1509192448395948, 1.1453031989244313, 1.1409633228412042, 1.1391377105162694, 1.1422647673350115, 1.1351347749049847, 1.1317315330872169, 1.1358092794051537, 1.1270367342692156, 1.1220297240293944, 1.1287718965457036, 1.1229915848145118, 1.1276325377134175, 1.1157567753241613, 1.104491882599317, 1.0997322958249311, 1.0985555259081035, 1.1091989187093882, 1.1011737401668842, 1.1043084905697749, 1.102460576937749, 1.0930094535534198, 1.093326917061439, 1.0899869341116686, 1.0916802630974696, 1.08188501229653, 1.0735914477935204, 1.0723507610651164, 1.0786341795554528, 1.067636590737563, 1.078506080003885, 1.0699827097929442, 1.055952548980713, 1.053299633356241, 1.05184445472864, 1.0480006910287416, 1.0421454562590673, 1.0334058174720178, 1.0244308778872857, 1.0352823367485633, 1.0278354103748615, 1.0238354412408976, 1.0238122848364024, 1.0169081481603475, 1.0271224998510802, 1.023240784039864, 1.0137880306977491, 1.0052133752749517, 1.005034559048139, 1.0011459657779107, 1.0161774846223683, 1.0073809027671814, 1.0146834460588603, 1.003075897693634, 1.0063373469389403, 0.9942306394760425, 0.9871316620936761, 1.0000702440738678, 0.995072637613003, 0.986417639714021, 0.9893957605728736, 0.9948934431259449, 0.9751725357312423, 0.9787977635860443, 0.9866193326619955, 0.9950639445048112, 0.9836145135072561, 0.970630583854822, 0.9704220661750207, 0.9629213580718408, 0.958994950239475, 0.949890157351127, 0.951893143928968, 0.9514228197244498, 0.9455427389878494, 0.9582221347552079, 0.9521965384483337, 0.9572379795404581, 0.9626255929470062, 0.9451672251407917, 0.9525189537268418, 0.9606815943351159, 0.9415912559399238, 0.9373168555589823, 0.9449755939153525, 0.9417428007492652, 0.9282635335738842, 0.9261100613153898, 0.9175571088607495, 0.9211325141099783, 0.9248134447978094, 0.9252288731244894, 0.9235585308991946, 0.9203333144004529, 0.9213451926524823, 0.908508089872507, 0.893067499765983, 0.8812150015280797, 0.8770722425900973, 0.8663665010378911, 0.8693721111004169, 0.8644681206116309, 0.8622608643311721, 0.8612014009402349, 0.8534854971445524, 0.8506980034021231, 0.8500102666708139, 0.8515842717427474, 0.8441836192057683, 0.8434125689359812, 0.846578985452652, 0.8418945899376502, 0.8405778591449444, 0.8410894939532647, 0.8377272761785067]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.9950126439710207, None, None, None, None, None, None, None, None, None, 1.7938135411812643, None, None, None, None, None, None, None, None, None, 1.7717145569644972, None, None, None, None, None, None, None, None, None, 1.676692353989289, None, None, None, None, None, None, None, None, None, 1.6423484380163293, None, None, None, None, None, None, None, None, None, 1.577425451074615, None, None, None, None, None, None, None, None, None, 1.5195799432582637, None, None, None, None, None, None, None, None, None, 1.4779543190781361, None, None, None, None, None, None, None, None, None, 1.464721017964566, None, None, None, None, None, None, None, None, None, 1.4339659000966403, None, None, None, None, None, None, None, None, None, 1.4121839162669605, None, None, None, None, None, None, None, None, None, 1.3940966058165427, None, None, None, None, None, None, None, None, None, 1.3814811895524544, None, None, None, None, None, None, None, None, None, 1.3507036978829114, None, None, None, None, None, None, None, None, None, 1.381458281177293, None, None, None, None, None, None, None, None, None, 1.3320385206528929, None, None, None, None, None, None, None, None, None, 1.3200832911109694, None, None, None, None, None, None, None, None, None, 1.3216908326560004, None, None, None, None, None, None, None, None, None, 1.2761681851958424, None, None, None, None, None, None, None, None, None, 1.2723977784926521]
best validation loss: 1.2723977784926521
training time: 9178.22 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=0, epoch=200, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.4864542942780714, 2.431398882315709, 2.2010079072071957, 2.132768140389369, 2.0198732568667483, 1.9695852811519916, 1.8289498870189373, 1.8475825878290029, 1.7765121459960938, 1.7441717340396001, 1.6943302200390742, 1.692308714756599, 1.6767509487959056, 1.6249423989882836, 1.6143484207300038, 1.6000256263292754, 1.6220206710008473, 1.606081458238455, 1.5766294598579407, 1.55543898160641, 1.5574974050888648, 1.5465712226354158, 1.518264930981856, 1.4999911922674913, 1.479483975813939, 1.46506674014605, 1.4609603606737578, 1.4948169955840478, 1.4710334356014545, 1.464401593575111, 1.4456787017675548, 1.4239963934971736, 1.4439023595589857, 1.423146435847649, 1.424447660262768, 1.4407049050697913, 1.410052010646233, 1.4026288986206055, 1.426145388529851, 1.382410297027001, 1.386060737646543, 1.3751161190179677, 1.3735459722005403, 1.3776793434069707, 1.3786363968482385, 1.3792175283798804, 1.3622606350825384, 1.3633956221433787, 1.364765112216656, 1.3637564778327942, 1.371001422405243, 1.3509884247413049, 1.3532016965059133, 1.3388306865325341, 1.3220547987864568, 1.3396585767085736, 1.3530000769175017, 1.3306113985868602, 1.3236237168312073, 1.3131606441277723, 1.3190400462884169, 1.3470437343303974, 1.3102961686941295, 1.297297097169436, 1.3115859719423146, 1.3113981852164636, 1.349703454054319, 1.2991216962154095, 1.3082778362127452, 1.3122339936403127, 1.2636329187796667, 1.2199658224215875, 1.1955900994630961, 1.193056963957273, 1.1835370843227093, 1.1860743921536665, 1.1635411290022044, 1.1532913331802075, 1.1463964306391203, 1.1410886416068444, 1.1408792229799123, 1.1412312388420105, 1.1273433405619402, 1.1196800149404085, 1.1153518099051256, 1.1144781639942756, 1.1072398263674517, 1.1126722212021167, 1.1059168370870442, 1.101069443500959, 1.0945979838187878, 1.0941356810239644, 1.0784498269741352, 1.081141662139159, 1.073887396317262, 1.0679319157050207, 1.0746513628042662, 1.0674112072357764, 1.070575516957503, 1.0718290943365831, 1.0595581783698156, 1.054847057049091, 1.0548558899989495, 1.057394415140152, 1.0485548950158632, 1.0444879210912263, 1.0445857391907618, 1.0426478385925293, 1.0381844846101909, 1.0342628474418933, 1.0378811611579015, 1.0262768176885753, 1.0213016065267415, 1.0185654140435731, 1.0101930842949793, 1.0201411522351778, 1.0083536849572108, 1.0068324827230895, 0.9911021636082575, 0.9971756178599137, 0.995961634012369, 0.9930088199101962, 1.0059350683138921, 1.0117188118971312, 1.0011527102727156, 0.9752070972552667, 0.9643332889446845, 0.9482984015574822, 0.9410527050495148, 0.9352038365143996, 0.9370513260364532, 0.9366147495233096, 0.9340515618140881, 0.9216610399576334, 0.9245846775861887, 0.9234991279932169, 0.9199761404440954, 0.9215125624950116, 0.9153949664189265, 0.9120702605981094, 0.9142608803052169, 0.9105755686759949, 0.9051567522379068, 0.9009668712432568, 0.9051941885397985, 0.8989297678837409, 0.9011949094442221, 0.9024446514936594, 0.9023075218384082, 0.8931091955074897, 0.8930517664322486, 0.8899952883903797, 0.8893372760369227, 0.8847850331893334, 0.8892974853515625, 0.8926949134239783, 0.8859485181478354, 0.8859522296832159, 0.8802870053511399, 0.8768489177410419, 0.8721335094708663, 0.8694278437357682, 0.872793055497683, 0.8705371709970328, 0.8692837678469144, 0.8668980552599981, 0.8663935798865098, 0.8627594227974231, 0.8579225631860586, 0.8545506413166339, 0.8550373017787933, 0.8557811837929946, 0.8519596640880291, 0.8536237432406499, 0.8518210718264947, 0.8443027115785159, 0.8479816661431239, 0.8445806938868302, 0.8447502072040851, 0.8418973065339602, 0.8452528508809897, 0.8426737189292908, 0.841038697040998, 0.8417191505432129, 0.8411937424769769, 0.8384993924544408, 0.8388880628805894, 0.8398816287517548, 0.8323574387110196, 0.8318817844757667, 0.829386653808447, 0.8268793500386752, 0.8247187779499934, 0.8259674517007974, 0.8282315799823174, 0.8222034046283135, 0.8208115972005404, 0.8167272164271429, 0.8201412650255057]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.9611919077855409, None, None, None, None, None, None, None, None, None, 1.8151218396055189, None, None, None, None, None, None, None, None, None, 1.741538574280259, None, None, None, None, None, None, None, None, None, 1.6800648092217587, None, None, None, None, None, None, None, None, None, 1.6649257646331304, None, None, None, None, None, None, None, None, None, 1.6010366853566829, None, None, None, None, None, None, None, None, None, 1.5564591586410172, None, None, None, None, None, None, None, None, None, 1.4375608651806173, None, None, None, None, None, None, None, None, None, 1.4052621405695203, None, None, None, None, None, None, None, None, None, 1.3978730489001927, None, None, None, None, None, None, None, None, None, 1.3709805542765934, None, None, None, None, None, None, None, None, None, 1.3351784823816033, None, None, None, None, None, None, None, None, None, 1.2976481735598546, None, None, None, None, None, None, None, None, None, 1.2931692858572965, None, None, None, None, None, None, None, None, None, 1.2885822683590733, None, None, None, None, None, None, None, None, None, 1.2763855326527784, None, None, None, None, None, None, None, None, None, 1.2619292960963098, None, None, None, None, None, None, None, None, None, 1.258694620503224, None, None, None, None, None, None, None, None, None, 1.2737059675835212, None, None, None, None, None, None, None, None, None, 1.2639241534374506]
best validation loss: 1.258694620503224
training time: 9716.93 seconds
changed reinit to ignore embedding layer
and each 10 epoch -> each 20 epoch
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=200, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.5375501926128683, 2.4498848685851464, 2.275171105678265, 2.1506066093078027, 1.994547032392942, 1.9117783537277808, 1.846408344232119, 1.8467419330890362, 1.7756199103135328, 1.7586979499230018, 1.6882203267170832, 1.7271504310461192, 1.6376691506459162, 1.6476730062411382, 1.6130297367389386, 1.5887009639006395, 1.588934627863077, 1.5567375008876507, 1.5442415384145884, 1.541852125754723, 1.5509449472794166, 1.528515407672295, 1.5379779568085303, 1.503096708884606, 1.507137064750378, 1.4578464398017297, 1.4867371733372028, 1.4731244811644921, 1.4613803395858178, 1.4470289945602417, 1.4555164942374597, 1.4090197269733136, 1.4318580260643592, 1.3986896322323725, 1.4150683054557214, 1.4031815437170176, 1.413012724656325, 1.3659031895490794, 1.351424446472755, 1.3813912730950575, 1.3815361949113698, 1.3923204311957726, 1.382403314113617, 1.3587173865391657, 1.3492092398496776, 1.3606848349938025, 1.3617453896082365, 1.3350207897332997, 1.341938935793363, 1.3515804547529955, 1.355017098096701, 1.3503983250031104, 1.3500190881582408, 1.3483386635780334, 1.2829845341352315, 1.2333140212755938, 1.2089076454822834, 1.1870094400185804, 1.181127843948511, 1.175219891163019, 1.1743983855614295, 1.1572610621268933, 1.1532106353686407, 1.1609967832381909, 1.1500404958541577, 1.1362255536592925, 1.1346909426725829, 1.126076659330955, 1.1175724565982819, 1.1132963047577784, 1.1129218018971956, 1.1149830061655779, 1.1115598036692693, 1.1036429703235626, 1.1008518223579113, 1.1017390512503111, 1.0859710023953364, 1.085003919326342, 1.0889275394953215, 1.0928242894319387, 1.0861995013860555, 1.084772302554204, 1.0749949354391832, 1.0735895840021281, 1.0634905031094184, 1.0593790274399977, 1.053099364042282, 1.0397059046305144, 1.042195771749203, 1.036717605132323, 1.0401219863158007, 1.0277257790932288, 1.0182583102813134, 1.0228633788915782, 1.0190238035642183, 1.0066684530331538, 1.011610407095689, 1.0130606500002055, 1.0118143833600557, 1.0053456884164076, 1.0197186309557695, 1.0052209083850567, 0.9987220145188845, 0.9914304889165438, 0.9777284447963421, 0.99563235273728, 0.9922560705588415, 0.9770744947286752, 0.9840213495951432, 0.9794533046392294, 0.970381695490617, 0.9741903589322016, 0.9695622829290537, 0.969056425186304, 0.9700375222242795, 0.9645677117200998, 0.968087531053103, 0.9621147765563085, 0.9573422395266019, 0.9590065685602335, 0.9588787509844854, 0.9556041680849515, 0.9478805569502023, 0.9734396109214196, 0.9427559880109934, 0.9357396364212036, 0.9229731834851779, 0.9424889248151046, 0.9295731645364028, 0.92866777915221, 0.9188762857363775, 0.9286595468337719, 0.9304992396097916, 0.9202493039461282, 0.9234891006579766, 0.9151529188339527, 0.9125344317692977, 0.9054000950776614, 0.9188291797271142, 0.9313823236868932, 0.9453208423577822, 0.9191653453386747, 0.9046410459738511, 0.9131437402505141, 0.9131626303379352, 0.9052671446250036, 0.9048504279210017, 0.9096681819512293, 0.9069679448237786, 0.8801958148296063, 0.8589647595699017, 0.8523600812141712, 0.8433484641405252, 0.8370442069493808, 0.8379166470124171, 0.8383648876960461, 0.833287605872521, 0.8329519904576815, 0.8353641445820148, 0.8287478203956897, 0.8344306922875918, 0.828450851715528, 0.8253786563873291, 0.8244214722743402, 0.8207087149986854, 0.8196756220780886, 0.8205702258990362, 0.8191503744858962, 0.8175808007900531, 0.8131790986427894, 0.8181393100665166, 0.8118715034081385, 0.8113176066141862, 0.807901178415005, 0.8068795043688554, 0.8102527833901919, 0.8054944941630731, 0.8014258581858414, 0.8021856340078207, 0.8020612826714149, 0.8049178971694066, 0.8039395488225497, 0.7981205055346856, 0.7954365473527175, 0.7969840077253488, 0.7938713981555059, 0.7934673566084641, 0.791159831560575, 0.7893964602397039, 0.7949954477640299, 0.7913967164663168, 0.7898597648510566, 0.7877340477246505, 0.7857012313145858, 0.7881120466268979, 0.7860008340615493, 0.7840716930536124, 0.7902654294784253, 0.7801495744631841]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.9712979891272897, None, None, None, None, None, None, None, None, None, 1.7626915090482158, None, None, None, None, None, None, None, None, None, 1.7180443688140281, None, None, None, None, None, None, None, None, None, 1.6446665411903745, None, None, None, None, None, None, None, None, None, 1.6235537332465233, None, None, None, None, None, None, None, None, None, 1.464506740883361, None, None, None, None, None, None, None, None, None, 1.4175708182897102, None, None, None, None, None, None, None, None, None, 1.4104677425442582, None, None, None, None, None, None, None, None, None, 1.3453563605539047, None, None, None, None, None, None, None, None, None, 1.3498338326192032, None, None, None, None, None, None, None, None, None, 1.3291728764934092, None, None, None, None, None, None, None, None, None, 1.3017686113239124, None, None, None, None, None, None, None, None, None, 1.3145710184604307, None, None, None, None, None, None, None, None, None, 1.3131423774722688, None, None, None, None, None, None, None, None, None, 1.2704670865755616, None, None, None, None, None, None, None, None, None, 1.2315911954968288, None, None, None, None, None, None, None, None, None, 1.2334756744489963, None, None, None, None, None, None, None, None, None, 1.2377939982684425, None, None, None, None, None, None, None, None, None, 1.2325446952388113, None, None, None, None, None, None, None, None, None, 1.227994966894981]
best validation loss: 1.227994966894981
training time: 9893.12 seconds
changed reinit not to ignore embedding layer
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=200, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.522893800185277, 2.5182696076539846, 2.2744728876994205, 2.2013384103775024, 2.085808116656083, 1.9895586967468262, 1.882429187114422, 1.8223874202141395, 1.7742871458713825, 1.7400983251058137, 1.682092350262862, 1.6746627275760357, 1.6661260678217962, 1.6284552399928753, 1.6848482122788062, 1.6298919916152954, 1.604338343326862, 1.564340279652522, 1.549894080712245, 1.5333786056591914, 1.5398302124096797, 1.530898928642273, 1.5509241819381714, 1.4842088451752296, 1.5034540020502531, 1.478069502573747, 1.4792684683432946, 1.4495111841421862, 1.46088150372872, 1.489220903469966, 1.444552339040316, 1.4121656096898592, 1.4149063871457026, 1.400189528098473, 1.4079192234919622, 1.390261471271515, 1.401293960901407, 1.389002602833968, 1.4025926131468553, 1.3850876688957214, 1.395167818436256, 1.3738600657536433, 1.3790427171266997, 1.3608512970117421, 1.3430920243263245, 1.338632854131552, 1.3443294901114244, 1.3269431040837214, 1.3388302463751574, 1.3528800698427053, 1.317553135064932, 1.3193205686715932, 1.2970510171009944, 1.3087165768329914, 1.304160631619967, 1.3117051216272206, 1.2914511011197016, 1.2896962257531972, 1.2735772820619435, 1.2943919255183294, 1.2916221526952891, 1.2825855108407826, 1.2946490553709178, 1.265969883937102, 1.2657449795649602, 1.2747019666891832, 1.2641175801937397, 1.241483048750804, 1.2617154946694007, 1.2599313029876122, 1.2643483647933373, 1.271907932483233, 1.2343215438035817, 1.2439202551658337, 1.253534239072066, 1.2230420823280628, 1.197887551326018, 1.2122789460879106, 1.2150625059237847, 1.2068199377793531, 1.2232551253758943, 1.2156169987641847, 1.2309902814718394, 1.174056433714353, 1.1278770657686086, 1.1209267125679896, 1.1062865119714003, 1.0975736746421227, 1.086970370549422, 1.0727183979291182, 1.070615603373601, 1.0641419749993544, 1.0625730867569263, 1.055614404953443, 1.0559934790317829, 1.047370122029231, 1.044921033657514, 1.04824560880661, 1.0322840855671809, 1.0268084819500263, 1.0358395668176503, 1.028206664782304, 1.0176987602160528, 1.0165446354792669, 1.0112838309544783, 1.0063503201191242, 1.0031359631281633, 0.9955352132137005, 0.9955622049478384, 1.004536814414538, 0.997919486119197, 1.0062204553530767, 0.995843366934703, 0.9900624729119815, 0.9834199593617365, 0.9839278757572174, 0.9747643745862521, 0.975766081076402, 0.964466569515375, 0.9592099052209121, 0.969842635668241, 0.9692297256909884, 0.9636233678230872, 0.9613535220806415, 0.9569163803870862, 0.9699968901964334, 0.9647219456159152, 0.9664824513288645, 0.9642795507724469, 0.9591348377557901, 0.9608621276341952, 0.9355155252493345, 0.9183911979198456, 0.9058179007126734, 0.9007848684604352, 0.8944982978013846, 0.8920613481448247, 0.8877094686031342, 0.8823980941222265, 0.8874760155494397, 0.8885289453543149, 0.8897624772328597, 0.8808224843098567, 0.877055280483686, 0.8786619580709017, 0.87540658391439, 0.8688793526245997, 0.869857017810528, 0.866260439157486, 0.8609625146939204, 0.8666164760406201, 0.8653632058547094, 0.8672224535391881, 0.8598454548762395, 0.8570679380343511, 0.8592078112638913, 0.8578662115793961, 0.8561078699735495, 0.859804031940607, 0.850902069073457, 0.8496121534934411, 0.8521532760216639, 0.8505473939272074, 0.8474328724237589, 0.8451987573733697, 0.8437138474904574, 0.8400386846982516, 0.8429595575882838, 0.8364885220160851, 0.8395335078239441, 0.8328070136216971, 0.8346477426015414, 0.8336314650682303, 0.8272491028675666, 0.8300182521343231, 0.8252688210744125, 0.8297626972198486, 0.83108117717963, 0.8233052904789264, 0.8197820599262531, 0.8267973615573003, 0.8229808027927692, 0.8203751284342545, 0.815248211989036, 0.8136892639673673, 0.8152871154821836, 0.8090165922274957, 0.8121274709701538, 0.8111082338369809, 0.8091603563382075, 0.8049350701845609, 0.801354169845581, 0.8068379851487967, 0.8125511614175943, 0.8097084966989664, 0.8011678296786088, 0.8062223402353433, 0.8009224900832543, 0.800110434110348]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.959630909923188, None, None, None, None, None, None, None, None, None, 1.7804308186962778, None, None, None, None, None, None, None, None, None, 1.771923998057519, None, None, None, None, None, None, None, None, None, 1.6639979446846869, None, None, None, None, None, None, None, None, None, 1.6960559465786, None, None, None, None, None, None, None, None, None, 1.5606423701558794, None, None, None, None, None, None, None, None, None, 1.574032411042145, None, None, None, None, None, None, None, None, None, 1.5248594126692732, None, None, None, None, None, None, None, None, None, 1.387313232786904, None, None, None, None, None, None, None, None, None, 1.3578344768900121, None, None, None, None, None, None, None, None, None, 1.3550124050911254, None, None, None, None, None, None, None, None, None, 1.3200412361718143, None, None, None, None, None, None, None, None, None, 1.3285664677835503, None, None, None, None, None, None, None, None, None, 1.279947742235955, None, None, None, None, None, None, None, None, None, 1.2707739461251524, None, None, None, None, None, None, None, None, None, 1.26938351857655, None, None, None, None, None, None, None, None, None, 1.264479310631824, None, None, None, None, None, None, None, None, None, 1.2675621590749409, None, None, None, None, None, None, None, None, None, 1.2666044994030032, None, None, None, None, None, None, None, None, None, 1.276890713562083]
best validation loss: 1.264479310631824
training time: 10106.70 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=10, epoch=400, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.129200009199289, 2.5375501926128683, 2.4498848685851464, 2.275171105678265, 2.1506066093078027, 1.994547032392942, 1.9117783537277808, 1.846408344232119, 1.8467419330890362, 1.7756199103135328, 1.7586979499230018, 1.6882203267170832, 1.7271504310461192, 1.6376691506459162, 1.6476730062411382, 1.6130297367389386, 1.5887009639006395, 1.588934627863077, 1.5567375008876507, 1.5442415384145884, 1.541852125754723, 1.5509449472794166, 1.528515407672295, 1.5379779568085303, 1.503096708884606, 1.507137064750378, 1.4578464398017297, 1.4867371733372028, 1.4731244811644921, 1.4613803395858178, 1.4470289945602417, 1.4555164942374597, 1.4090197269733136, 1.4318580260643592, 1.3986896322323725, 1.4150683054557214, 1.4031815437170176, 1.413012724656325, 1.3659031895490794, 1.351424446472755, 1.3813912730950575, 1.3815361949113698, 1.3923204311957726, 1.382403314113617, 1.3587173865391657, 1.3492092398496776, 1.3606848349938025, 1.3617453896082365, 1.3350207897332997, 1.341938935793363, 1.3515804547529955, 1.355017098096701, 1.3503983250031104, 1.3500190881582408, 1.3483386635780334, 1.2829845341352315, 1.2333140212755938, 1.2089076454822834, 1.1870094400185804, 1.181127843948511, 1.175219891163019, 1.1743983855614295, 1.1572610621268933, 1.1532106353686407, 1.1609967832381909, 1.1500404958541577, 1.1362255536592925, 1.1346909426725829, 1.126076659330955, 1.1175724565982819, 1.1132963047577784, 1.1129218018971956, 1.1149830061655779, 1.1115598036692693, 1.1036429703235626, 1.1008518223579113, 1.1017390512503111, 1.0859710023953364, 1.085003919326342, 1.0889275394953215, 1.0928242894319387, 1.0861995013860555, 1.084772302554204, 1.0749949354391832, 1.0735895840021281, 1.0634905031094184, 1.0593790274399977, 1.053099364042282, 1.0397059046305144, 1.042195771749203, 1.036717605132323, 1.0401219863158007, 1.0277257790932288, 1.0182583102813134, 1.0228633788915782, 1.0190238035642183, 1.0066684530331538, 1.011610407095689, 1.0130606500002055, 1.0118143833600557, 1.0053456884164076, 1.0197186309557695, 1.0052209083850567, 0.9987220145188845, 0.9914304889165438, 0.9777284447963421, 0.99563235273728, 0.9922560705588415, 0.9770744947286752, 0.9840213495951432, 0.9794533046392294, 0.970381695490617, 0.9741903589322016, 0.9695622829290537, 0.969056425186304, 0.9700375222242795, 0.9645677117200998, 0.968087531053103, 0.9621147765563085, 0.9573422395266019, 0.9590065685602335, 0.9588787509844854, 0.9556041680849515, 0.9478805569502023, 0.9734396109214196, 0.9427559880109934, 0.9357396364212036, 0.9229731834851779, 0.9424889248151046, 0.9295731645364028, 0.92866777915221, 0.9188762857363775, 0.9286595468337719, 0.9304992396097916, 0.9202493039461282, 0.9234891006579766, 0.9151529188339527, 0.9125344317692977, 0.9054000950776614, 0.9188291797271142, 0.9313823236868932, 0.9453208423577822, 0.9191653453386747, 0.9046410459738511, 0.9131437402505141, 0.9131626303379352, 0.9052671446250036, 0.9048504279210017, 0.9096681819512293, 0.9069679448237786, 0.8801958148296063, 0.8589647595699017, 0.8523600812141712, 0.8433484641405252, 0.8370442069493808, 0.8379166470124171, 0.8383648876960461, 0.833287605872521, 0.8329519904576815, 0.8353641445820148, 0.8287478203956897, 0.8344306922875918, 0.828450851715528, 0.8253786563873291, 0.8244214722743402, 0.8207087149986854, 0.8196756220780886, 0.8205702258990362, 0.8191503744858962, 0.8175808007900531, 0.8131790986427894, 0.8181393100665166, 0.8118715034081385, 0.8113176066141862, 0.807901178415005, 0.8068795043688554, 0.8102527833901919, 0.8054944941630731, 0.8014258581858414, 0.8021856340078207, 0.8020612826714149, 0.8049178971694066, 0.8039395488225497, 0.7981205055346856, 0.7954365473527175, 0.7969840077253488, 0.7938713981555059, 0.7934673566084641, 0.791159831560575, 0.7893964602397039, 0.7949954477640299, 0.7913967164663168, 0.7898597648510566, 0.7877340477246505, 0.7857012313145858, 0.7881120466268979, 0.7860008340615493, 0.7840716930536124, 0.7902654294784253, 0.7801495744631841, 0.78164198077642, 0.782165392087056, 0.779390601011423, 0.7738907039165497, 0.7749200050647442, 0.7774648322508886, 0.7721606378371899, 0.7707830552871411, 0.7717050749521989, 0.7705269983181586, 0.7758547503214616, 0.7714318633079529, 0.7743680454217471, 0.7735259074431199, 0.7698819935321808, 0.7667362162700067, 0.7654845531170185, 0.7633585952795469, 0.762497752904892, 0.7584531467694503, 0.7611445050973159, 0.762464722761741, 0.7594702977400559, 0.7599561076897842, 0.760751146536607, 0.7583261751211606, 0.7605911424526801, 0.7581155575238742, 0.7502347253836118, 0.7536830099729391, 0.7506886009986584, 0.7549092196501218, 0.7487548429232377, 0.7542594052278079, 0.7501280743342179, 0.7448266905087692, 0.7469481894603143, 0.7481196614412161, 0.7504365994380071, 0.7435287626890036, 0.7432018724771646, 0.7435775238734025, 0.7448158653882834, 0.743566497014119, 0.7404367854961982, 0.7423272430896759, 0.7399219274520874, 0.7356811211659358, 0.7401057390066293, 0.7348180229847248, 0.7432017578528478, 0.7365919557901529, 0.7352268856305343, 0.7332418813155248, 0.728538806621845, 0.7313393171016986, 0.7343611258726853, 0.7309895180738889, 0.7350284250882956, 0.7307297770793622, 0.726252250946485, 0.7267091457660382, 0.7237974221889789, 0.7247686042235448, 0.7231964996227851, 0.7213064271670121, 0.7189264228710761, 0.7189360650686117, 0.7148437820948087, 0.7159997820854187, 0.7174803889714755, 0.7205741428411924, 0.717318608210637, 0.7151031402441171, 0.7176281030361469, 0.7064158664299891, 0.6995753737596365, 0.6932559105066153, 0.6976234821172861, 0.6929147083025712, 0.6942524818273691, 0.6960368202282832, 0.6890237308465518, 0.695825301683866, 0.6882404547471267, 0.6899200907120338, 0.68637009538137, 0.6894872417816749, 0.6854766882382907, 0.6853231925230759, 0.6834092805018792, 0.6831668110994192, 0.6810557773480048, 0.6809175381293664, 0.6776387439324305, 0.6810179948806763, 0.6801209266369159, 0.6803964353524722, 0.6792743939619797, 0.6776020183013036, 0.6789220365194174, 0.6735652799789722, 0.6741352493946369, 0.6739454521582677, 0.6702715273086841, 0.6708355270899259, 0.6687326820997092, 0.6660445538850931, 0.6679901297275836, 0.6680224285675929, 0.6666705883466281, 0.6659376460772294, 0.666227365915592, 0.6664964121121627, 0.6667807400226593, 0.6657100457411546, 0.6636119370277112, 0.6669439788048084, 0.6634131601223578, 0.6614077985286713, 0.6625296290104206, 0.6660169844443982, 0.6626613759077512, 0.6642879453989176, 0.6630097444240863, 0.6641093011085804, 0.6599647930035224, 0.6583684522372025, 0.6601990828147302, 0.6578410886801206, 0.6588246478484228, 0.6630159754019517, 0.6579236709154569, 0.6592867649518527, 0.6598254671463599, 0.6564455307446994, 0.656023614681684, 0.6552063089150649, 0.6541360135261829, 0.6542826363673577, 0.653974677507694, 0.6571874366356776, 0.6569591508461878, 0.6567094463568467, 0.6562770009040833, 0.6575309657133542, 0.65842117025302, 0.6571028186724737, 0.6569814361058749, 0.6544397679659036, 0.6556701499682206, 0.652984217955516, 0.6522181194562179, 0.6559187861589285, 0.6518792510032654, 0.6524866200410403, 0.6548414551294767, 0.6530613647057459, 0.6560124044234936, 0.6516268230401553, 0.6508590441483718, 0.6536788596556737, 0.6549932956695557, 0.6520715493422288, 0.6539199077166044, 0.6540109927837665, 0.6512692020489619, 0.6548268886712881, 0.6500500784470484, 0.6525592276683221, 0.6518468856811523, 0.6533601054778466, 0.6509461471667657, 0.6535799640875596, 0.6514391692785116, 0.6520217244441693, 0.6520823607077966, 0.6505424403227292, 0.648245463004479, 0.6493082000659063, 0.6506014672609476, 0.6516158259831942, 0.654592534670463, 0.6514628002276788, 0.6503285582248981, 0.6526366105446448, 0.6518921783337226, 0.651003374503209, 0.6507517993450165, 0.649861448086225, 0.6491815516581902, 0.6475291366760547, 0.6490739217171302, 0.6506467094788184, 0.6492939339234278, 0.6497316933595217, 0.6503708706452296, 0.6492636112066416, 0.6487602660289178, 0.6515892606515151]
validation loss history: [None, None, None, None, None, None, None, None, None, 1.9712979891272897, None, None, None, None, None, None, None, None, None, 1.7626915090482158, None, None, None, None, None, None, None, None, None, 1.7180443688140281, None, None, None, None, None, None, None, None, None, 1.6446665411903745, None, None, None, None, None, None, None, None, None, 1.6235537332465233, None, None, None, None, None, None, None, None, None, 1.464506740883361, None, None, None, None, None, None, None, None, None, 1.4175708182897102, None, None, None, None, None, None, None, None, None, 1.4104677425442582, None, None, None, None, None, None, None, None, None, 1.3453563605539047, None, None, None, None, None, None, None, None, None, 1.3498338326192032, None, None, None, None, None, None, None, None, None, 1.3291728764934092, None, None, None, None, None, None, None, None, None, 1.3017686113239124, None, None, None, None, None, None, None, None, None, 1.3145710184604307, None, None, None, None, None, None, None, None, None, 1.3131423774722688, None, None, None, None, None, None, None, None, None, 1.2704670865755616, None, None, None, None, None, None, None, None, None, 1.2315911954968288, None, None, None, None, None, None, None, None, None, 1.2334756744489963, None, None, None, None, None, None, None, None, None, 1.2377939982684425, None, None, None, None, None, None, None, None, None, 1.2325446952388113, None, None, None, None, None, None, None, None, None, 1.227994966894981, None, None, None, None, None, None, None, None, None, 1.2344705524252007, None, None, None, None, None, None, None, None, None, 1.2340041144990719, None, None, None, None, None, None, None, None, None, 1.242326249265757, None, None, None, None, None, None, None, None, None, 1.2358289746867381, None, None, None, None, None, None, None, None, None, 1.249524444072199, None, None, None, None, None, None, None, None, None, 1.2368426449763048, None, None, None, None, None, None, None, None, None, 1.261613056090598, None, None, None, None, None, None, None, None, None, 1.2510403495297653, None, None, None, None, None, None, None, None, None, 1.258817110491345, None, None, None, None, None, None, None, None, None, 1.2657236145015507, None, None, None, None, None, None, None, None, None, 1.2672397091023673, None, None, None, None, None, None, None, None, None, 1.2695639027465604, None, None, None, None, None, None, None, None, None, 1.275125305684235, None, None, None, None, None, None, None, None, None, 1.2762754292930731, None, None, None, None, None, None, None, None, None, 1.2807114181603345, None, None, None, None, None, None, None, None, None, 1.2815722694520566, None, None, None, None, None, None, None, None, None, 1.2847345968267154, None, None, None, None, None, None, None, None, None, 1.2853385315306436, None, None, None, None, None, None, None, None, None, 1.2848015599505165, None, None, None, None, None, None, None, None, None, 1.2847851382062117]
best validation loss: 1.227994966894981
training time: 19997.09 seconds
model config: ModelConfig(vocab_size=10000, dim_model=1024, dim_ff=1024, num_layers=6, num_heads=8, dropout=0.1, batch_size=64, max_len=1024, learning_rate=0.0005, reinit_percent=0, epoch=300, pad_token_id=0, device='cpu', valid_pred_cnt=1, seed=18)
train loss history: [4.138011556405288, 2.5042424293664785, 2.405696905576266, 2.221840656720675, 2.1222999554414015, 2.0045828773425174, 1.9224555354851942, 1.8317859906416674, 1.8721948586977446, 1.758599776488084, 1.7519844724581792, 1.7101730475058923, 1.6744160835559552, 1.6512916775850148, 1.6848368232066815, 1.6108513978811412, 1.6051251521477332, 1.5956940696789668, 1.5927758858754084, 1.5401429763207068, 1.5578551429968615, 1.5333295647914593, 1.5262376574369578, 1.5415076109079213, 1.5190555865948017, 1.5171693930259118, 1.5429422351030202, 1.5007328299375682, 1.496127949311183, 1.4743901903812702, 1.4848787096830516, 1.4747078739679778, 1.4388001010968134, 1.462641110787025, 1.4254929377482488, 1.425589905335353, 1.4309370105083172, 1.4532868220255926, 1.4176583656897912, 1.417260298362145, 1.3940878372925978, 1.402517868922307, 1.3753211360711317, 1.3824946605242217, 1.3786102945987995, 1.3884784212479224, 1.380849343079787, 1.3750936618218055, 1.3830183056684642, 1.3901357742456288, 1.3800369134316077, 1.3604667370135968, 1.3436185396634615, 1.368104705443749, 1.3539968774868891, 1.3497063334171588, 1.3430814422093904, 1.32517808675766, 1.3125064556415265, 1.329012591105241, 1.3233448404532213, 1.3561671513777513, 1.344249046765841, 1.3163188237410326, 1.31654004408763, 1.2689731121063232, 1.2329137669159815, 1.2149668909036195, 1.2204476273976839, 1.1979832007334783, 1.1936524900106282, 1.1803208566628969, 1.176543306845885, 1.1748760732320638, 1.1772719369484828, 1.188515488918011, 1.177711926973783, 1.1737980177769294, 1.1726535329451928, 1.1649758884539971, 1.1614604821571937, 1.162118680202044, 1.15832565839474, 1.1642487782698412, 1.1522692831662984, 1.1472137730855207, 1.1467423943372874, 1.1419851848712335, 1.1449901048953717, 1.1472575343572176, 1.139361629119286, 1.145944962134728, 1.136566854440249, 1.1274876021421874, 1.128504406947356, 1.1160845779455626, 1.1152635721059947, 1.1086984345546136, 1.1040071822129762, 1.1032889783382416, 1.106823565868231, 1.1043860958172724, 1.1000627783628611, 1.0966684887042413, 1.0914087272607362, 1.087289104094872, 1.0950736541014452, 1.0919596667473133, 1.0944223679029024, 1.0888900871460254, 1.0839230624529033, 1.0802626609802246, 1.0823570031386156, 1.068289685707826, 1.0687406292328467, 1.0649213103147654, 1.068531749340204, 1.0669442392312563, 1.0625732770332923, 1.0644564789075117, 1.0768098464378943, 1.0639002093902001, 1.050920525422463, 1.0482538961447203, 1.045442494062277, 1.0508382251629462, 1.0525586994794698, 1.0450721566493695, 1.0508832014524019, 1.039586365222931, 1.0440985422867994, 1.032785789324687, 1.0348334243664374, 1.0359559403016017, 1.0363691265766437, 1.0471399174286768, 1.0288149164273188, 1.016972466157033, 1.0057054620522718, 1.0055505564579597, 1.0029760392812581, 0.998475948205361, 1.0164274756725018, 1.0052778308208172, 1.0062263355805323, 1.0017364644087279, 1.0043517488699694, 0.9824853860414945, 0.9804886946311364, 0.9853385663949527, 0.9867061582895426, 0.9883319001931411, 0.9928248410041516, 0.9868179651407095, 0.9985370888159826, 0.9582870900630951, 0.9445665409931769, 0.9298186714832599, 0.9277797914468325, 0.9242360889911652, 0.9192080428967109, 0.9181094123766973, 0.9135902157196631, 0.9123215675354004, 0.9093988904586205, 0.9081410559324118, 0.9052980152460245, 0.8986193812810458, 0.8984097242355347, 0.8993682884252988, 0.9067950202868535, 0.8988732351706579, 0.8968342290474818, 0.8941526504663321, 0.8894141155939835, 0.8877378312441019, 0.8842812065894787, 0.8818422166200784, 0.8819658045585339, 0.8891455852068387, 0.882569663799726, 0.8819289803504944, 0.8800958945200994, 0.8780745015694544, 0.8831946230851687, 0.8734323244828445, 0.8755316986487462, 0.8724914628725785, 0.8679285966433011, 0.8624848219064566, 0.8680416781168717, 0.8696328837137955, 0.8614001342883477, 0.8641803149993603, 0.8621013668867258, 0.859877368578544, 0.8610324194798102, 0.8592926722306472, 0.8543467819690704, 0.8549959109379694, 0.8533063026574942, 0.849969187608132, 0.857377840922429, 0.8557870044158056, 0.8504981467357049, 0.8500629617617681, 0.8526588219862717, 0.8476882806191077, 0.8423835956133329, 0.8467007600344144, 0.8470603754887214, 0.8447360969506778, 0.8392259432719305, 0.8404459517735702, 0.8398979008197784, 0.8438943899594821, 0.8424470791449914, 0.842115370126871, 0.8399066902123965, 0.8401781779069167, 0.8362126717200646, 0.8353269971334017, 0.83235086615269, 0.8274374420826252, 0.8293862113585839, 0.8263310858836541, 0.8304919646336482, 0.8270138227022611, 0.8191810869253598, 0.8196462438656733, 0.8158663900998923, 0.8138639330863953, 0.8105135101538438, 0.811874100795159, 0.8092682980574094, 0.8081246660305903, 0.8050609712417309, 0.8094347921701578, 0.80425219810926, 0.8047504631372598, 0.8019455327437475, 0.8009421412761395, 0.8048866437031672, 0.8037604231100816, 0.7997638858281649, 0.8000303988273327, 0.798749600465481, 0.8022809257874122, 0.7983266688310183, 0.7950788896817428, 0.7962468587435209, 0.7909142695940458, 0.7911861928609701, 0.7939772330797635, 0.7942173389288095, 0.793657646729396, 0.7898175510076376, 0.7907213156039898, 0.7902490886358114, 0.7925178064749792, 0.7886077326077682, 0.7903615878178523, 0.7882615534158853, 0.7858082812566024, 0.7852813120071704, 0.7845248786302713, 0.7870181432137122, 0.7826802845184619, 0.7839988768100739, 0.782086934034641, 0.7827455126322233, 0.7803171781393198, 0.780244515492366, 0.7764987005637243, 0.7791494108163394, 0.779714802136788, 0.7753905699803278, 0.7782261234063369, 0.7738775175351363, 0.773157197695512, 0.7726054718861213, 0.7727490227956039, 0.7708283914969518, 0.7754855499817774, 0.7700622356854953, 0.7716178733568925, 0.7706570143883045, 0.7699824892557584, 0.7706674360311948, 0.7677595752936143, 0.771179749415471, 0.7663172437594488, 0.7649207917543558, 0.7676902459217951, 0.7624106957362249, 0.7653871522499964, 0.7631377233908727, 0.7608811144645398, 0.7626975453816928, 0.761689727122967]
validation loss history: [None, None, None, None, None, None, None, None, None, 2.076006378302594, None, None, None, None, None, None, None, None, None, 1.816739852130952, None, None, None, None, None, None, None, None, None, 1.7271369993866317, None, None, None, None, None, None, None, None, None, 1.665551497068227, None, None, None, None, None, None, None, None, None, 1.6559602602049843, None, None, None, None, None, None, None, None, None, 1.5767652525680478, None, None, None, None, None, None, None, None, None, 1.489315774693699, None, None, None, None, None, None, None, None, None, 1.468088202694944, None, None, None, None, None, None, None, None, None, 1.4392634011881404, None, None, None, None, None, None, None, None, None, 1.3997596033802229, None, None, None, None, None, None, None, None, None, 1.392753310883311, None, None, None, None, None, None, None, None, None, 1.3950077155902487, None, None, None, None, None, None, None, None, None, 1.3427535444947163, None, None, None, None, None, None, None, None, None, 1.3192025095026776, None, None, None, None, None, None, None, None, None, 1.3001203843094342, None, None, None, None, None, None, None, None, None, 1.2584671652266748, None, None, None, None, None, None, None, None, None, 1.248216530621375, None, None, None, None, None, None, None, None, None, 1.2411329178223773, None, None, None, None, None, None, None, None, None, 1.2345362223006646, None, None, None, None, None, None, None, None, None, 1.2365343941486766, None, None, None, None, None, None, None, None, None, 1.2296332527241698, None, None, None, None, None, None, None, None, None, 1.2309108562251039, None, None, None, None, None, None, None, None, None, 1.2157192814774078, None, None, None, None, None, None, None, None, None, 1.215116338172255, None, None, None, None, None, None, None, None, None, 1.2137438312505224, None, None, None, None, None, None, None, None, None, 1.2190541353406785, None, None, None, None, None, None, None, None, None, 1.220036676233256, None, None, None, None, None, None, None, None, None, 1.219472119361252, None, None, None, None, None, None, None, None, None, 1.2229686473204904, None, None, None, None, None, None, None, None, None, 1.2286025081649468]
best validation loss: 1.2137438312505224
training time: 10638.87 seconds
